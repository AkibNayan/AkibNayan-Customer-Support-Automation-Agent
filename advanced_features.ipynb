{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "356a63d9",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Advanced Features for AI Agent Automation\n",
    "Including memory, tool integration, and multi-agent collaboration\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2075be66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, List, Dict, Any, Optional\n",
    "from datetime import datetime\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.tools import tool\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6132c272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "451cfe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ENHANCED STATE WITH MEMORY\n",
    "# ============================================================================\n",
    "class EnhancedAgentState(TypedDict):\n",
    "    \"\"\"Enhanced state with conversation history and memory.\"\"\"\n",
    "    query: str\n",
    "    conversation_history: List[Dict[str, str]]\n",
    "    category: str\n",
    "    retrieved_data: str\n",
    "    response: str\n",
    "    quality_score: int\n",
    "    timestamp: str\n",
    "    metadata: Dict[str, Any]\n",
    "    user_context: Dict[str, Any]    # User preferences, where key is str and value is Any\n",
    "    tools_used: List[str]\n",
    "    multi_agent_results: Dict[str, Any]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "712bbd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MEMORY MANAGEMENT\n",
    "# ============================================================================\n",
    "class ConversationMemory:\n",
    "    \"\"\"Manages conversation history and context\"\"\"\n",
    "    def __init__(self, max_history: int = 10):\n",
    "        self.max_history = max_history\n",
    "        self.conversations: Dict[str, List[Dict]] = {}\n",
    "    \n",
    "    def add_message(self, user_id: str, role: str, content: str):\n",
    "        \"\"\"Add messages to the conversation history\"\"\"\n",
    "        if user_id not in self.conversations:\n",
    "            self.conversations[user_id] = []\n",
    "        \n",
    "        self.conversations[user_id].append({\n",
    "            \"role\": role,\n",
    "            \"content\": content,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        })\n",
    "        \n",
    "        # Keep only the recent history\n",
    "        if len(self.conversations[user_id]) > self.max_history:\n",
    "            self.conversations[user_id] = self.conversations[user_id][-self.max_history:]\n",
    "        \n",
    "    def get_history(self, user_id: str) -> List[Dict]:\n",
    "        \"\"\"Get the conversation history for a user\"\"\"\n",
    "        return self.conversations.get(user_id, [])\n",
    "    \n",
    "    def clear_history(self, user_id: str):\n",
    "        \"\"\"Clear the conversation history for a user\"\"\"\n",
    "        if user_id in self.conversations:\n",
    "            del self.conversations[user_id]\n",
    "            \n",
    "# Global Memory Instance\n",
    "memory = ConversationMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97955ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CUSTOM TOOLS\n",
    "# ============================================================================\n",
    "@tool\n",
    "def search_order_database(order_id: str) -> str:\n",
    "    \"\"\"Search the order database for order information\"\"\"\n",
    "    # Simulate the database lookup\n",
    "    mock_orders = {\n",
    "        \"12345\": {\n",
    "            \"status\": \"In Transit\",\n",
    "            \"expected_delivery\": \"2024-12-15\",\n",
    "            \"tracking_number\": \"TRK123456789\"\n",
    "        },\n",
    "        \"67890\": {\n",
    "            \"status\": \"Delivered\",\n",
    "            \"expected_delivery\": \"2024-12-10\",\n",
    "            \"tracking_number\": \"TRK987654321\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    order_info = mock_orders.get(order_id, None)\n",
    "    if order_info:\n",
    "        return json.dumps(order_info)\n",
    "    return json.dumps({\"error\": \"Order not found\"})\n",
    "\n",
    "@tool\n",
    "def check_inventory(product_id: str) -> str:\n",
    "    \"\"\"Check product inventory levels\"\"\"\n",
    "    # Simulate the inventory check\n",
    "    mock_inventory = {\n",
    "        \"PROD001\": {\n",
    "            \"in_stock\": True,\n",
    "            \"quantity\": 150\n",
    "        },\n",
    "        \"PROD002\": {\n",
    "            \"in_stock\": False,\n",
    "            \"quantity\": 0\n",
    "        },\n",
    "        \"PROD003\": {\n",
    "            \"in_stock\": True,\n",
    "            \"quantity\": 45\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    inventory = mock_inventory.get(product_id, {\"in_stock\": False, \"quantity\": 0})\n",
    "    # returns a JSON string\n",
    "    return json.dumps(inventory)\n",
    "    \n",
    "@tool\n",
    "def calculate_refund(order_id: str, return_reason: str) -> str:\n",
    "    \"\"\"Calculate refund amount based on order_id and return_reason\"\"\"\n",
    "    # Simulate refund calculation\n",
    "    refund_rules = {\n",
    "        \"defective\": 1.0,   # 100% refund\n",
    "        \"wrong_item\": 1.0,\n",
    "        \"not_satisfied\": 0.8,   # 80% refund restocking fee\n",
    "        \"change_mind\": 0.7\n",
    "    }\n",
    "    \n",
    "    refund_percentage = refund_rules.get(return_reason.lower(), 0.7)\n",
    "    estimated_amount = 99.99    # Mock order amount\n",
    "    refund_amount = estimated_amount * refund_percentage\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"refund_amount\": round(refund_amount, 2),\n",
    "        \"refund_percentage\": refund_percentage * 100,\n",
    "        \"processing_time\": \"5-7 business days\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7bf7253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TOOL EXECUTOR NODE\n",
    "# ============================================================================\n",
    "def tool_executor_node(state: EnhancedAgentState) -> EnhancedAgentState:\n",
    "    \"\"\"Execute appropriate tools based on query category\"\"\"\n",
    "    category = state.get('category', '')\n",
    "    query = state.get('query', '')\n",
    "    tools_used = []\n",
    "    tool_results = {}\n",
    "    \n",
    "    # Determine which tools to use\n",
    "    if category == 'ORDER_STATUS' and '#' in query:\n",
    "        # Extract the order id\n",
    "        order_id = query.split(\"#\")[-1].split()[0]\n",
    "        result = search_order_database.invoke({\"order_id\": order_id})\n",
    "        \n",
    "        tool_results['order_info'] = result\n",
    "        tools_used.append('search_order_database')\n",
    "    \n",
    "    elif category == 'REFUND':\n",
    "        # Extract the order id\n",
    "        #order_id = query.split(\"#\")[-1].split()[0]\n",
    "        #Mock order id extraction\n",
    "        order_id = \"12345\"\n",
    "        result = calculate_refund.invoke({\n",
    "            \"order_id\": order_id,\n",
    "            \"return_reason\": \"defective\"\n",
    "        })\n",
    "        tool_results['refund_info'] = result\n",
    "        tools_used.append('calculate_refund')\n",
    "        \n",
    "    # Add tool results to the retrieved data \n",
    "    enhanced_data = state.get('retrieved_data', '')\n",
    "    \n",
    "    if tool_results:\n",
    "        enhanced_data += f\"\\n\\nTools Results: {json.dumps(tool_results, indent=2)}\"\n",
    "        \n",
    "    return {\n",
    "        **state, \n",
    "        \"retrieved_data\": enhanced_data,\n",
    "        \"tools_used\": tools_used,\n",
    "        \"metadata\": {\n",
    "            **state.get(\"metadata\", {}),\n",
    "            \"tools_executed\": tools_used\n",
    "        }\n",
    "    }\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19976deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MULTI-AGENT COLLABORATION\n",
    "# ============================================================================\n",
    "class SpecializedAgent:\n",
    "    \"\"\"Base class for specialized agents\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, expertise: str):\n",
    "        self.name = name\n",
    "        self.expertise = expertise\n",
    "        self.llm = ChatGroq(\n",
    "            model=\"llama-3.3-70b-versatile\",\n",
    "            temperature=0.7,\n",
    "            groq_api_key=os.getenv(\"GROQ_API_KEY\", \"\")\n",
    "        )\n",
    "        \n",
    "    def process(self, query: str, context: str) -> str:\n",
    "        \"\"\"Process query with specialized knowledge\"\"\"\n",
    "        prompt = f\"\"\"You are a {self.expertise} specialist.\n",
    "        \n",
    "        Context: {context}\n",
    "        Query: {query}\n",
    "        \n",
    "        Provide a specialized response based on your expertise.\"\"\"\n",
    "        \n",
    "        messages = [HumanMessage(content=prompt)]\n",
    "        response = self.llm.invoke(messages)\n",
    "        \n",
    "        return response.content\n",
    "    \n",
    "class TechnicalSupportAgent(SpecializedAgent):\n",
    "    \"\"\"Agent specialized in technical support\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"TechSupport\", \"technical support and troubleshooting\")\n",
    "\n",
    "class RefundSpecialistAgent(SpecializedAgent):\n",
    "    \"\"\"Agent specialized in refunds and returns\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"RefundSpecialist\", \"refund processing and return\")\n",
    "    \n",
    "class OrderManagementAgent(SpecializedAgent):\n",
    "    \"\"\"Agent specialized in order management\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"OrderManagement\", \"order tracking and logistics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0576081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MULTI-AGENT COORDINATOR\n",
    "# ============================================================================\n",
    "def multi_agent_coordinator_node(state: EnhancedAgentState) -> EnhancedAgentState:\n",
    "    \"\"\"Coordinate multiple specialized agents\"\"\"\n",
    "    category = state.get(\"category\", \"\")\n",
    "    query = state.get(\"query\", \"\")\n",
    "    context = state.get(\"retrieved_data\", \"\")\n",
    "    \n",
    "    #Select appropriate specialized agent\n",
    "    specialized_response = None\n",
    "    agent_name = None\n",
    "    \n",
    "    if category == \"TECHNICAL_SUPPORT\":\n",
    "        agent = TechnicalSupportAgent()\n",
    "        specialized_response = agent.process(query, context)\n",
    "        agent_name = agent.name\n",
    "    \n",
    "    elif category == \"REFUND\":\n",
    "        agent = RefundSpecialistAgent()\n",
    "        specialized_response = agent.process(query, context)\n",
    "        agent_name = agent.name\n",
    "    \n",
    "    elif category == \"ORDER_MANAGEMENT\":\n",
    "        agent = OrderManagementAgent()\n",
    "        specialized_response = agent.process(query, context)\n",
    "        agent_name = agent.name\n",
    "    \n",
    "    multi_agent_results = {\n",
    "        \"agent_used\": agent_name,\n",
    "        \"specialized_response\": specialized_response\n",
    "    }\n",
    "    \n",
    "    #Use specialized response if available\n",
    "    if specialized_response:\n",
    "        state[\"response\"] = specialized_response\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"multi_agent_results\": multi_agent_results,\n",
    "        \"metadata\": {\n",
    "            **state.get(\"metadata\", {}),\n",
    "            \"multi_agent_used\": agent_name is not None  #True if an agent name was provided\n",
    "        }\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a779112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONTEXT-AWARE RESPONSE NODE\n",
    "# ============================================================================\n",
    "def context_aware_response_node(state: EnhancedAgentState) -> EnhancedAgentState:\n",
    "    \"\"\"Generate response with conversation history awareness.\"\"\"\n",
    "    llm = ChatGroq(\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        temperature=0.7,\n",
    "        groq_api_key=os.getenv(\"GROQ_API_KEY\", \"\")\n",
    "    )\n",
    "    \n",
    "    # Build conversation context\n",
    "    history = state.get(\"conversation_history\", [])\n",
    "    #Consider last 5 messages\n",
    "    history_text = \"\\n\".join([f\"{msg['role']}: {msg['content']}\" for msg in history[-5:]]) if history else \"No previous conversation\"\n",
    "    \n",
    "    # Get User Context\n",
    "    user_context = state.get(\"user_context\", {})\n",
    "    user_info = f\"User Preferences: {json.dumps(user_context)}\" if user_context else \"\"\n",
    "    \n",
    "    system_prompt = f\"\"\"You are a context-aware customer support agent.\n",
    "    \n",
    "    Previous conversation:\n",
    "    {history_text}\n",
    "    {user_info}\n",
    "    \n",
    "    Use the conversation history to provide personalized and contextual reponses.\"\"\"\n",
    "    \n",
    "    user_prompt = f\"\"\"Current query: {state['query']}\n",
    "    \n",
    "    Available information: {state['retrieved_data']}\n",
    "    \n",
    "    Provide a helpful, contextual response that considers the conversation history.\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=user_prompt)\n",
    "    ]\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    return {\n",
    "        **state, \n",
    "        \"response\": response.content,\n",
    "        \"metadata\": {\n",
    "            **state.get(\"metadata\", {}),\n",
    "            \"context_aware\": True\n",
    "        }\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07ae4660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SENTIMENT ANALYSIS NODE\n",
    "# ============================================================================\n",
    "def sentiment_analysis_node(state: EnhancedAgentState) -> EnhancedAgentState:\n",
    "    \"\"\"Analyze sentiment and adjust response accordingly.\"\"\"\n",
    "    \n",
    "    llm = ChatGroq(\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        temperature=0.7,\n",
    "        groq_api_key=os.getenv(\"GROQ_API_KEY\", \"\")\n",
    "    )\n",
    "    \n",
    "    prompt = f\"\"\"Analyze the sentiment of this customer query: {state['query']}\n",
    "    \n",
    "    Respond with ONLY one word: POSITIVE, NEUTRAL, NEGATIVE, or URGENT\"\"\"\n",
    "    \n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    response = llm.invoke(messages)\n",
    "    sentiment = response.content.strip()\n",
    "    \n",
    "    # Adjust response tone based on sentiment\n",
    "    if sentiment in ['NEGATIVE', 'URGENT']:\n",
    "        # Add empathy and prioritize resolution\n",
    "        adjusted_response = f\"I understand your concern and I'm here to help. {state.get('response', '')}\"\n",
    "        state['response'] = adjusted_response\n",
    "        state['metadata']['priority'] = 'high'\n",
    "        \n",
    "    state['metadata']['sentiment'] = sentiment\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b9f899cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ENHANCED WORKFLOW\n",
    "# ============================================================================\n",
    "def create_enhanced_workflow():\n",
    "    \"\"\"Create enhanced workflow with advanced features.\"\"\"\n",
    "    from langgraph_agent import (classify_query_node,\n",
    "                                 retrieve_data_node,\n",
    "                                 generate_response_node,\n",
    "                                 quality_check_node)\n",
    "    \n",
    "    workflow = StateGraph(EnhancedAgentState)\n",
    "    \n",
    "    # Add all nodes\n",
    "    workflow.add_node(\"classifier\", classify_query_node)\n",
    "    workflow.add_node(\"sentiment_analyzer\", sentiment_analysis_node)\n",
    "    workflow.add_node(\"retriever\", retrieve_data_node)\n",
    "    workflow.add_node(\"tool_executor\", tool_executor_node)\n",
    "    workflow.add_node(\"multi-agent\", multi_agent_coordinator_node)\n",
    "    workflow.add_node(\"context_aware_generator\", context_aware_response_node)\n",
    "    workflow.add_node(\"quality_checker\", quality_check_node)\n",
    "    \n",
    "    # Define flow\n",
    "    workflow.set_entry_point(\"classifier\")\n",
    "    workflow.add_edge(\"classifier\", \"sentiment_analyzer\")\n",
    "    workflow.add_edge(\"sentiment_analyzer\", \"retriever\")\n",
    "    workflow.add_edge(\"retriever\", \"tool_executor\")\n",
    "    workflow.add_edge(\"tool_executor\", \"multi-agent\")\n",
    "    workflow.add_edge(\"multi-agent\", \"context_aware_generator\")\n",
    "    workflow.add_edge(\"context_aware_generator\", \"quality_checker\")\n",
    "    workflow.add_edge(\"quality_checker\", END)\n",
    "    \n",
    "    return workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3257ce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# USAGE EXAMPLE\n",
    "# ============================================================================\n",
    "def run_enhanced_agent(query: str, user_id: str = \"default_user\"):\n",
    "    \"\"\"Run enhanced agent with all features\"\"\"\n",
    "    # Get conversation history\n",
    "    history = memory.get_history(user_id)\n",
    "    \n",
    "    #Mock user context \n",
    "    user_context = {\n",
    "        \"user_id\": user_id,\n",
    "        \"preferred_language\": \"English\",\n",
    "        \"vip_status\": False\n",
    "    }\n",
    "    \n",
    "    #Initial state\n",
    "    initial_state = {\n",
    "        \"query\": query,\n",
    "        \"conversation_history\": history,\n",
    "        \"category\": \"\",\n",
    "        \"retrieved_data\": \"\",\n",
    "        \"response\": \"\",\n",
    "        \"quality_score\": 0,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"metadata\": {},\n",
    "        \"user_context\": user_context,\n",
    "        \"tools_used\": [],\n",
    "        \"multi_agent_results\": {}\n",
    "    }\n",
    "    \n",
    "    # Run the workflow\n",
    "    app = create_enhanced_workflow()\n",
    "    result = app.invoke(initial_state)\n",
    "    \n",
    "    #Update memory\n",
    "    memory.add_message(user_id, \"user\", query)\n",
    "    memory.add_message(user_id, \"assistant\", result[\"response\"])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "64447b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 21:41:20,270 - langgraph_agent - INFO - Classifying query: What's the status of my order #12345?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced AI Agent with Enhanced Features\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Query: What's the status of my order #12345?\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 21:41:20,873 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-11-26 21:41:21,139 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 21:41:21,139 - langgraph_agent - INFO - Query classified as: ORDER_STATUS\n",
      "2025-11-26 21:41:22,026 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 21:41:22,028 - langgraph_agent - INFO - Retrieving data for category: ORDER_STATUS\n",
      "2025-11-26 21:41:22,029 - langgraph_agent - INFO - Data retrieved successfully for ORDER_STATUS\n",
      "2025-11-26 21:41:23,636 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 21:41:23,639 - langgraph_agent - INFO - Performing quality check\n",
      "2025-11-26 21:41:24,322 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-11-26 21:41:24,686 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 21:41:24,690 - root - INFO - Quality score: 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: ORDER_STATUS\n",
      "Sentiment: NEUTRAL\n",
      "Tools Used: search_order_database\n",
      "Multi-Agent: None\n",
      "\n",
      "Response:\n",
      "Hello again, test_user_001. I see you're inquiring about the status of your order #12345 for the third time. I apologize for the continued inconvenience, but unfortunately, our order tracking system is still unable to locate your order. As I mentioned earlier, it's possible that the order may not have been processed yet or there might be an issue with the order number.\n",
      "\n",
      "I've checked again, and the system confirms that the order cannot be found. I understand this can be frustrating, and I'm here to help. At this point, I'd like to explore alternative solutions to assist you. Can you please confirm if you've received any order confirmation emails or if you have a receipt for the order? This might help me investigate further.\n",
      "\n",
      "If you're still unable to find any information, I can offer to help you place a new order or provide more information on our typical delivery times, which are 3-5 business days. Please let me know how I can assist you further.\n",
      "\n",
      "Quality Score: 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 21:41:26,262 - langgraph_agent - INFO - Classifying query: I received a defective product and need a refund\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Query: I received a defective product and need a refund\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 21:41:26,855 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-11-26 21:41:27,238 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 21:41:27,238 - langgraph_agent - INFO - Query classified as: REFUND\n",
      "2025-11-26 21:41:28,122 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 21:41:28,122 - langgraph_agent - INFO - Retrieving data for category: REFUND\n",
      "2025-11-26 21:41:28,122 - langgraph_agent - INFO - Data retrieved successfully for REFUND\n",
      "2025-11-26 21:41:29,447 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 21:41:31,253 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 21:41:31,272 - langgraph_agent - INFO - Performing quality check\n",
      "2025-11-26 21:41:31,858 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-11-26 21:41:32,086 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 21:41:32,086 - root - INFO - Quality score: 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: REFUND\n",
      "Sentiment: NEGATIVE\n",
      "Tools Used: calculate_refund\n",
      "Multi-Agent: RefundSpecialist\n",
      "\n",
      "Response:\n",
      "Hello again, test_user_001. I apologize for the continued issues you're experiencing with your order. Unfortunately, our previous conversations were unable to locate your order #12345 in our system. However, I'm here to help you with your new concern regarding the defective product you received.\n",
      "\n",
      "I understand that you're requesting a refund, and I'd be happy to guide you through the process. According to our refund policy, you have a 30-day return window to initiate a refund. Since you've mentioned that the product is defective, I'll do my best to assist you.\n",
      "\n",
      "To process your refund, I'll need you to provide a receipt for the order. Please confirm if you have the receipt available. Once I have that information, I can proceed with the refund.\n",
      "\n",
      "As per our refund information, you're eligible for a full refund of $99.99, which is 100% of the original amount. Please note that our processing time for refunds is 5-7 business days.\n",
      "\n",
      "Before we move forward, I want to ensure that we've resolved the issue with your order #12345. If you're still unsure about the status of your original order, I can try to investigate further. However, since you've received a defective product, I'll prioritize the refund process for you.\n",
      "\n",
      "Please let me know how you'd like to proceed, and I'll do my best to assist you in resolving this matter.\n",
      "\n",
      "Quality Score: 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 21:41:33,163 - langgraph_agent - INFO - Classifying query: I'm having trouble resetting my password\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Query: I'm having trouble resetting my password\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 21:41:33,755 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-11-26 21:41:34,059 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 21:41:34,063 - langgraph_agent - INFO - Query classified as: TECHNICAL_SUPPORT\n",
      "2025-11-26 21:41:35,176 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 21:41:35,180 - langgraph_agent - INFO - Retrieving data for category: TECHNICAL_SUPPORT\n",
      "2025-11-26 21:41:35,182 - langgraph_agent - INFO - Data retrieved successfully for TECHNICAL_SUPPORT\n",
      "2025-11-26 21:41:36,919 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 21:41:38,569 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 21:41:38,582 - langgraph_agent - INFO - Performing quality check\n",
      "2025-11-26 21:41:39,191 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-11-26 21:41:39,439 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 21:41:39,442 - root - INFO - Quality score: 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: TECHNICAL_SUPPORT\n",
      "Sentiment: NEUTRAL\n",
      "Tools Used: None\n",
      "Multi-Agent: TechSupport\n",
      "\n",
      "Response:\n",
      "Hello again, test_user_001. I see you're experiencing a new issue - trouble resetting your password. I apologize for the inconvenience, especially considering the frustration you've already faced with your order #12345 and the defective product.\n",
      "\n",
      "Don't worry, I'm here to help you with the password reset. Since you've already had to deal with some challenges, I'll make sure to guide you through this process as smoothly as possible. To reset your password, you can try clicking on the \"Forgot Password\" link on our login page. If you're still having trouble, I can provide you with a password reset link or assist you in verifying your account information to ensure a successful reset.\n",
      "\n",
      "Please let me know if you've already tried the \"Forgot Password\" link or if you'd like me to send you a password reset link. Additionally, if you have any other questions or concerns, feel free to ask. I'm here to help you 24/7, and I'll do my best to get you back up and running as quickly as possible.\n",
      "\n",
      "Quality Score: 9/10\n",
      "\n",
      " Enhanced agent demonstration completed!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EXAMPLE EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Enhanced AI Agent with Enhanced Features\\n\")\n",
    "    \n",
    "    # Test queries\n",
    "    queries = [\n",
    "        \"What's the status of my order #12345?\",\n",
    "        \"I received a defective product and need a refund\",\n",
    "        \"I'm having trouble resetting my password\"\n",
    "    ]\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Query: {query}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        result = run_enhanced_agent(query, user_id=\"test_user_001\")\n",
    "        \n",
    "        print(f\"Category: {result['category']}\")\n",
    "        print(f\"Sentiment: {result['metadata'].get('sentiment', 'N/A')}\")\n",
    "        print(f\"Tools Used: {', '.join(result['tools_used']) if result['tools_used'] else 'None'}\")\n",
    "        print(f\"Multi-Agent: {result['multi_agent_results'].get('agent_used', 'N/A')}\")\n",
    "        print(f\"\\nResponse:\\n{result['response']}\")\n",
    "        print(f\"\\nQuality Score: {result['quality_score']}/10\")\n",
    "        \n",
    "        input(\"\\nPress Enter to continue...\")\n",
    "        \n",
    "    print(\"\\n Enhanced agent demonstration completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c388c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
