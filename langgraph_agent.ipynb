{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e0733ff",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "AI Agent Automation with LangGraph - Complete Implementation\n",
    "Customer Support Automation System using Groq API\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed340778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, Annotated, Literal\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "import operator\n",
    "from datetime import datetime\n",
    "import json\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b667bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f46ec9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7586db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STATE DEFINITION\n",
    "# ============================================================================\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    category: str\n",
    "    retrieved_data: str\n",
    "    response: str\n",
    "    quality_score: int\n",
    "    timestamp: str\n",
    "    metadata: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbde9894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "class Config:\n",
    "    \"\"\"Configuration for AI Agent System\"\"\"\n",
    "    GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "    MODEL_NAME = \"llama-3.3-70b-versatile\"\n",
    "    TEMPERATURE = 0.7\n",
    "    MAX_TOKENS = 1000\n",
    "    \n",
    "    #Knowledge Base Simulation\n",
    "    KNOWLEDGE_BASE = {\n",
    "        'ORDER_STATUS': {\n",
    "            \"data\": \"Order tracking system connected. Typical delivery: 3-5 business days.\",\n",
    "            \"context\": \"Customer inquiring about order status\"\n",
    "        },\n",
    "        'REFUND': {\n",
    "            \"data\": \"Refund policy: 30-day return window. Full refund with receipt. Processing time: 5-7 business days.\",\n",
    "            \"context\": \"Customer requesting refund information\"\n",
    "        },\n",
    "        'SHIPPING': {\n",
    "            \"data\": \"Shipping options: Standard (5-7 days, $5.99), Express (2-3 days, $12.99), Overnight ($24.99).\",\n",
    "            \"context\": \"Customer inquiring about shipping\"\n",
    "        },\n",
    "        'POLICY': {\n",
    "            \"data\": \"Return policy: 30 days, original condition. Warranty: 1 year manufacturer warranty on electronics.\",\n",
    "            \"context\": \"Customer asking about policies\"\n",
    "        },\n",
    "        'TECHNICAL_SUPPORT': {\n",
    "            \"data\": \"Technical support available 24/7. Common issues: password reset, account access, product setup.\",\n",
    "            \"context\": \"Customer needs technical assistance\"\n",
    "        },\n",
    "        'GENERAL': {\n",
    "            \"data\": \"General customer support. Business hours: Mon-Fri 9AM-6PM EST. Contact: support@company.com\",\n",
    "            \"context\": \"General inquiry\"\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2a0467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LLM INITIALIZATION\n",
    "# ============================================================================\n",
    "def initialize_llm():\n",
    "    \"\"\"Initialize the Groq LLM\"\"\"\n",
    "    try:\n",
    "        llm = ChatGroq(\n",
    "            model=Config.MODEL_NAME,\n",
    "            temperature=Config.TEMPERATURE,\n",
    "            max_tokens=Config.MAX_TOKENS,\n",
    "            groq_api_key=Config.GROQ_API_KEY\n",
    "        )\n",
    "        logger.info(\"LLM initialized successfully\")\n",
    "        return llm\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialized LLM: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c62d09ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# AGENT NODES\n",
    "# ============================================================================\n",
    "def classify_query_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Node 1: Classify the incoming query into categories\n",
    "    \"\"\"\n",
    "    logger.info(f\"Classifying query: {state['query']}\")\n",
    "    \n",
    "    try:\n",
    "        llm = initialize_llm()\n",
    "        \n",
    "        prompt = f\"\"\"Analyze this customer support query and classify it into ONE of this categories:\n",
    "        - ORDER_STATUS: Questions about order tracking, delivery status\n",
    "        - REFUND: Refund requests, return inquiries\n",
    "        - SHIPPING: Shipping methods, costs, delivery times\n",
    "        - POLICY: Return policies, warranties, terms\n",
    "        - TECHNICAL_SUPPORT: Technical issues, troubleshooting\n",
    "        - GENERAL: Everything else\n",
    "        \n",
    "        Query: {state['query']}\n",
    "        \n",
    "        Responde with ONLY the category name, nothing else.\"\"\"\n",
    "        \n",
    "        messages = [HumanMessage(content=prompt)]\n",
    "        response = llm.invoke(messages)\n",
    "        category = response.content.strip()\n",
    "        \n",
    "        logger.info(f\"Query classified as: {category}\")\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"category\": category,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"metadata\": {\n",
    "                \"node\": \"classifier\",\n",
    "                \"status\": \"completed\"\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in classify_query_node: {e}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"category\": \"GENERAL\",\n",
    "            \"metadata\": {\n",
    "                \"node\": \"classifier\",\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "745b74dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Node 2: Retrieve relevant data based on classification\n",
    "    \"\"\"\n",
    "    logger.info(f\"Retrieving data for category: {state['category']}\")\n",
    "    \n",
    "    try:\n",
    "        category = state.get('category', \"GENERAL\")\n",
    "        \n",
    "        # Retrieve from knowledge base\n",
    "        knowledge = Config.KNOWLEDGE_BASE.get(category, Config.KNOWLEDGE_BASE[\"GENERAL\"])\n",
    "        retrieved_data = knowledge[\"data\"]\n",
    "        \n",
    "        logger.info(f\"Data retrieved successfully for {category}\")\n",
    "        \n",
    "        # Return updated state\n",
    "        return {\n",
    "            **state, # Unpack the previous state\n",
    "            \"retrieved_data\": retrieved_data,\n",
    "            \"metadata\": {\n",
    "                **state.get(\"metadata\", {}),\n",
    "                \"retriever\": \"completed\",\n",
    "                \"data_source\": \"knowledge_base\"\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error retrieved_data_node: {e}\")\n",
    "        return {\n",
    "            **state, \n",
    "            \"retrieved_data\": \"Error retrieving data\",\n",
    "            \"metadata\": {\n",
    "                **state.get(\"metadata\", {}),\n",
    "                \"retriever\": \"error\"\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd119885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Node 3: Generate a helpful response using LLM\n",
    "    \"\"\"\n",
    "    logger.info(\"Generating response\")\n",
    "    \n",
    "    try:\n",
    "        llm = initialize_llm()\n",
    "        \n",
    "        system_prompt = \"\"\"You are a professional and friendly customer support agent. Your goal is to provide helpful, acurate and empathetic reponses to customer queries. Keep responses concise but complete. Be professional yet warm\"\"\"\n",
    "        \n",
    "        user_prompt = f\"\"\"Based on this information: {state['retrieved_data']}, Provide a helpful response to this customer query: {state['query']}. Make the response personal, professionl and actionable.\"\"\"\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=system_prompt),\n",
    "            HumanMessage(content=user_prompt)\n",
    "        ]\n",
    "        \n",
    "        response = llm.invoke(messages)\n",
    "        generated_response = response.content.strip()\n",
    "        \n",
    "        logger.info(f\"Response generated successfully\")\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"response\": generated_response,\n",
    "            \"metadata\": {\n",
    "                **state.get(\"metadata\", {}),\n",
    "                \"generator\": \"completed\"\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in generate_response_node: {e}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"response\": \"I appologize, but I'm having trouble generating a response. Please try again.\",\n",
    "            \"metadata\": {\n",
    "                **state.get(\"metadata\", {}),\n",
    "                \"generator\": \"error\"\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "429b5971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_check_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Node 4: Check the quality of the generated response.\n",
    "    \"\"\"\n",
    "    logger.info(\"Performing quality check\")\n",
    "    \n",
    "    try:\n",
    "        llm = initialize_llm()\n",
    "        \n",
    "        prompt = f\"\"\"Evaluate this customer support response on a scale of 1-10:\n",
    "        \n",
    "        Original Query: {state['query']}\n",
    "        Response: {state['response']}\n",
    "        \n",
    "        Consider:\n",
    "        - Relevance to the query\n",
    "        - Helpfulness and completeness\n",
    "        - Professionalism and tone\n",
    "        - Clarity and conciseness\n",
    "        \n",
    "        Respond with ONLY a number from 1-10, nothing else\n",
    "        \"\"\"\n",
    "        \n",
    "        messages = [HumanMessage(content=prompt)]\n",
    "        response = llm.invoke(messages)\n",
    "        \n",
    "        try:\n",
    "            quality_score = int(response.content.strip())\n",
    "        except ValueError:\n",
    "            quality_score = 7 # Default score if parsing fails\n",
    "        \n",
    "        logging.info(f\"Quality score: {quality_score}/10\")\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"quality_score\": quality_score,\n",
    "            \"metadata\": {\n",
    "                **state.get(\"metadata\", {}),\n",
    "                \"quality_checker\": \"completed\",\n",
    "                \"final_status\": \"success\"\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in quality_check_node: {e}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"quality_score\": 0,\n",
    "            \"metadata\": {\n",
    "                **state.get(\"metadata\", {}),\n",
    "                \"quality_checker\": \"error\",\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fec10cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_regenerate(state: AgentState) -> Literal[\"regenerate\", \"end\"]:\n",
    "    \"\"\"\n",
    "    Conditional Edge: Decide if response needs regeneration.\n",
    "    \"\"\"\n",
    "    quality_score = state.get(\"quality_score\", 0)\n",
    "    \n",
    "    # If quality score is too low, regenerate (max 1 retry to avoid loops)\n",
    "    retry_count = state.get(\"metadata\", {}).get(\"retry_count\", 0)\n",
    "    \n",
    "    if quality_score < 6 and retry_count < 1:\n",
    "        logger.info(f\"Quality score too low ({quality_score}/10), regenerating...\")\n",
    "        return \"regenerate\"\n",
    "    return \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0636cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
