{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e0733ff",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "AI Agent Automation with LangGraph - Complete Implementation\n",
    "Customer Support Automation System using Groq API\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed340778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, Annotated, Literal\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "import operator\n",
    "from datetime import datetime\n",
    "import json\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b667bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f46ec9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7586db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STATE DEFINITION\n",
    "# ============================================================================\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    category: str\n",
    "    retrieved_data: str\n",
    "    response: str\n",
    "    quality_score: int\n",
    "    timestamp: str\n",
    "    metadata: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbde9894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "class Config:\n",
    "    \"\"\"Configuration for AI Agent System\"\"\"\n",
    "    GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "    MODEL_NAME = \"llama-3.3-70b-versatile\"\n",
    "    TEMPERATURE = 0.7\n",
    "    MAX_TOKENS = 1000\n",
    "    \n",
    "    #Knowledge Base Simulation\n",
    "    KNOWLEDGE_BASE = {\n",
    "        'ORDER_STATUS': {\n",
    "            \"data\": \"Order tracking system connected. Typical delivery: 3-5 business days.\",\n",
    "            \"context\": \"Customer inquiring about order status\"\n",
    "        },\n",
    "        'REFUND': {\n",
    "            \"data\": \"Refund policy: 30-day return window. Full refund with receipt. Processing time: 5-7 business days.\",\n",
    "            \"context\": \"Customer requesting refund information\"\n",
    "        },\n",
    "        'SHIPPING': {\n",
    "            \"data\": \"Shipping options: Standard (5-7 days, $5.99), Express (2-3 days, $12.99), Overnight ($24.99).\",\n",
    "            \"context\": \"Customer inquiring about shipping\"\n",
    "        },\n",
    "        'POLICY': {\n",
    "            \"data\": \"Return policy: 30 days, original condition. Warranty: 1 year manufacturer warranty on electronics.\",\n",
    "            \"context\": \"Customer asking about policies\"\n",
    "        },\n",
    "        'TECHNICAL_SUPPORT': {\n",
    "            \"data\": \"Technical support available 24/7. Common issues: password reset, account access, product setup.\",\n",
    "            \"context\": \"Customer needs technical assistance\"\n",
    "        },\n",
    "        'GENERAL': {\n",
    "            \"data\": \"General customer support. Business hours: Mon-Fri 9AM-6PM EST. Contact: support@company.com\",\n",
    "            \"context\": \"General inquiry\"\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2a0467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LLM INITIALIZATION\n",
    "# ============================================================================\n",
    "def initialize_llm():\n",
    "    \"\"\"Initialize the Groq LLM\"\"\"\n",
    "    try:\n",
    "        llm = ChatGroq(\n",
    "            model=Config.MODEL_NAME,\n",
    "            temperature=Config.TEMPERATURE,\n",
    "            max_tokens=Config.MAX_TOKENS,\n",
    "            groq_api_key=Config.GROQ_API_KEY\n",
    "        )\n",
    "        logger.info(\"LLM initialized successfully\")\n",
    "        return llm\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialized LLM: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c62d09ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# AGENT NODES\n",
    "# ============================================================================\n",
    "def classify_query_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Node 1: Classify the incoming query into categories\n",
    "    \"\"\"\n",
    "    logger.info(f\"Classifying query: {state['query']}\")\n",
    "    \n",
    "    try:\n",
    "        llm = initialize_llm()\n",
    "        \n",
    "        prompt = f\"\"\"Analyze this customer support query and classify it into ONE of this categories:\n",
    "        - ORDER_STATUS: Questions about order tracking, delivery status\n",
    "        - REFUND: Refund requests, return inquiries\n",
    "        - SHIPPING: Shipping methods, costs, delivery times\n",
    "        - POLICY: Return policies, warranties, terms\n",
    "        - TECHNICAL_SUPPORT: Technical issues, troubleshooting\n",
    "        - GENERAL: Everything else\n",
    "        \n",
    "        Query: {state['query']}\n",
    "        \n",
    "        Responde with ONLY the category name, nothing else.\"\"\"\n",
    "        \n",
    "        messages = [HumanMessage(content=prompt)]\n",
    "        response = llm.invoke(messages)\n",
    "        category = response.content.strip()\n",
    "        \n",
    "        logger.info(f\"Query classified as: {category}\")\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"category\": category,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"metadata\": {\n",
    "                \"node\": \"classifier\",\n",
    "                \"status\": \"completed\"\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in classify_query_node: {e}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"category\": \"GENERAL\",\n",
    "            \"metadata\": {\n",
    "                \"node\": \"classifier\",\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "745b74dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Node 2: Retrieve relevant data based on classification\n",
    "    \"\"\"\n",
    "    logger.info(f\"Retrieving data for category: {state['category']}\")\n",
    "    \n",
    "    try:\n",
    "        category = state.get('category', \"GENERAL\")\n",
    "        \n",
    "        # Retrieve from knowledge base\n",
    "        knowledge = Config.KNOWLEDGE_BASE.get(category, Config.KNOWLEDGE_BASE[\"GENERAL\"])\n",
    "        retrieved_data = knowledge[\"data\"]\n",
    "        \n",
    "        logger.info(f\"Data retrieved successfully for {category}\")\n",
    "        \n",
    "        # Return updated state\n",
    "        return {\n",
    "            **state, # Unpack the previous state\n",
    "            \"retrieved_data\": retrieved_data,\n",
    "            \"metadata\": {\n",
    "                **state.get(\"metadata\", {}),\n",
    "                \"retriever\": \"completed\",\n",
    "                \"data_source\": \"knowledge_base\"\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error retrieved_data_node: {e}\")\n",
    "        return {\n",
    "            **state, \n",
    "            \"retrieved_data\": \"Error retrieving data\",\n",
    "            \"metadata\": {\n",
    "                **state.get(\"metadata\", {}),\n",
    "                \"retriever\": \"error\"\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd119885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Node 3: Generate a helpful response using LLM\n",
    "    \"\"\"\n",
    "    logger.info(\"Generating response\")\n",
    "    \n",
    "    try:\n",
    "        llm = initialize_llm()\n",
    "        \n",
    "        system_prompt = \"\"\"You are a professional and friendly customer support agent. Your goal is to provide helpful, acurate and empathetic reponses to customer queries. Keep responses concise but complete. Be professional yet warm\"\"\"\n",
    "        \n",
    "        user_prompt = f\"\"\"Based on this information: {state['retrieved_data']}, Provide a helpful response to this customer query: {state['query']}. Make the response personal, professionl and actionable.\"\"\"\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=system_prompt),\n",
    "            HumanMessage(content=user_prompt)\n",
    "        ]\n",
    "        \n",
    "        response = llm.invoke(messages)\n",
    "        generated_response = response.content.strip()\n",
    "        \n",
    "        logger.info(f\"Response generated successfully\")\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"response\": generated_response,\n",
    "            \"metadata\": {\n",
    "                **state.get(\"metadata\", {}),\n",
    "                \"generator\": \"completed\"\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in generate_response_node: {e}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"response\": \"I appologize, but I'm having trouble generating a response. Please try again.\",\n",
    "            \"metadata\": {\n",
    "                **state.get(\"metadata\", {}),\n",
    "                \"generator\": \"error\"\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "429b5971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_check_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Node 4: Check the quality of the generated response.\n",
    "    \"\"\"\n",
    "    logger.info(\"Performing quality check\")\n",
    "    \n",
    "    try:\n",
    "        llm = initialize_llm()\n",
    "        \n",
    "        prompt = f\"\"\"Evaluate this customer support response on a scale of 1-10:\n",
    "        \n",
    "        Original Query: {state['query']}\n",
    "        Response: {state['response']}\n",
    "        \n",
    "        Consider:\n",
    "        - Relevance to the query\n",
    "        - Helpfulness and completeness\n",
    "        - Professionalism and tone\n",
    "        - Clarity and conciseness\n",
    "        \n",
    "        Respond with ONLY a number from 1-10, nothing else\n",
    "        \"\"\"\n",
    "        \n",
    "        messages = [HumanMessage(content=prompt)]\n",
    "        response = llm.invoke(messages)\n",
    "        \n",
    "        try:\n",
    "            quality_score = int(response.content.strip())\n",
    "        except ValueError:\n",
    "            quality_score = 7 # Default score if parsing fails\n",
    "        \n",
    "        logging.info(f\"Quality score: {quality_score}/10\")\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"quality_score\": quality_score,\n",
    "            \"metadata\": {\n",
    "                **state.get(\"metadata\", {}),\n",
    "                \"quality_checker\": \"completed\",\n",
    "                \"final_status\": \"success\"\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in quality_check_node: {e}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"quality_score\": 0,\n",
    "            \"metadata\": {\n",
    "                **state.get(\"metadata\", {}),\n",
    "                \"quality_checker\": \"error\",\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fec10cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_regenerate(state: AgentState) -> Literal[\"regenerate\", \"end\"]:\n",
    "    \"\"\"\n",
    "    Conditional Edge: Decide if response needs regeneration.\n",
    "    \"\"\"\n",
    "    quality_score = state.get(\"quality_score\", 0)\n",
    "    \n",
    "    # If quality score is too low, regenerate (max 1 retry to avoid loops)\n",
    "    retry_count = state.get(\"metadata\", {}).get(\"retry_count\", 0)\n",
    "    \n",
    "    if quality_score < 6 and retry_count < 1:\n",
    "        logger.info(f\"Quality score too low ({quality_score}/10), regenerating...\")\n",
    "        return \"regenerate\"\n",
    "    return \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df0636cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# GRAPH CONSTRUCTION\n",
    "# ============================================================================\n",
    "def create_agent_workflow():\n",
    "    \"\"\"\n",
    "    Create and compile the Langgraph workflow.\n",
    "    \"\"\"\n",
    "    logger.info(\"Creating agent workflow graph\")\n",
    "    \n",
    "    #Initialize the graph\n",
    "    workflow = StateGraph(AgentState)\n",
    "    \n",
    "    # Add Nodes\n",
    "    workflow.add_node(\"classifier\", classify_query_node)\n",
    "    workflow.add_node(\"retriever\", retrieve_data_node)\n",
    "    workflow.add_node(\"generator\", generate_response_node)\n",
    "    workflow.add_node(\"quality_checker\", quality_check_node)\n",
    "    \n",
    "    # Define the flow\n",
    "    workflow.set_entry_point(\"classifier\")\n",
    "    workflow.add_edge(\"classifier\", \"retriever\")\n",
    "    workflow.add_edge(\"retriever\", \"generator\")\n",
    "    workflow.add_edge(\"generator\", \"quality_checker\")\n",
    "    \n",
    "    # Conditional edge for regeneration\n",
    "    workflow.add_conditional_edges(\n",
    "        \"quality_checker\",\n",
    "        should_regenerate,\n",
    "        {\n",
    "            \"regenerate\": \"generator\",\n",
    "            \"end\": END\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    #Compile the graph\n",
    "    app = workflow.compile()\n",
    "    \n",
    "    logger.info(\"Workflow compiled successfully\")\n",
    "    return app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd5e82f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "def run_agent(query: str):\n",
    "    \"\"\"\n",
    "    Run the agent workflow with a given query\n",
    "    \"\"\"\n",
    "    logger.info(f\"Starting agent workflow for query: {query}\")\n",
    "    \n",
    "    # Create the workflow\n",
    "    app = create_agent_workflow()\n",
    "    \n",
    "    initial_state = {\n",
    "        \"query\": query,\n",
    "        \"category\": \"\",\n",
    "        \"retrieved_data\": \"\",\n",
    "        \"response\": \"\",\n",
    "        \"quality_score\": 0,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"metadata\": {\n",
    "            \"retry_count\": 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Run the workflow\n",
    "    try:\n",
    "        final_state = app.invoke(initial_state)\n",
    "        logger.info(\"Workflow completed successfully\")\n",
    "        return final_state\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error running workflow: {e}\")\n",
    "        raise\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04f2ef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(result: AgentState):\n",
    "    \"\"\"\n",
    "    Display the results in a formatted way.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"AI Agent Automation Results\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nOriginal Query: {result['query']}\")\n",
    "    print(f\"\\nCategory: {result['category']}\")\n",
    "    print(f\"\\nRetrieved Data: {result['retrieved_data']}\")\n",
    "    print(f\"\\nGenerated Response: {result['response']}/10\")\n",
    "    print(f\"\\nQuality Score: {result['quality_score']}\")\n",
    "    print(f\"\\nTimestamp: {result['timestamp']}\")\n",
    "    print(f\"\\nMetadata: {json.dumps(result.get(\"metadata\", {}), indent=2)}\")\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7ce4fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 23:35:03,760 - __main__ - INFO - Starting agent workflow for query: What's the status of my order #12345?\n",
      "2025-11-26 23:35:03,762 - __main__ - INFO - Creating agent workflow graph\n",
      "2025-11-26 23:35:03,786 - __main__ - INFO - Workflow compiled successfully\n",
      "2025-11-26 23:35:03,805 - __main__ - INFO - Classifying query: What's the status of my order #12345?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– AI Agent Automation with LangGraph\n",
      "Using Groq API with Llama 3.3 70B\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST CASE 1/5\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 23:35:04,858 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-26 23:35:05,155 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 23:35:05,187 - __main__ - INFO - Query classified as: ORDER_STATUS\n",
      "2025-11-26 23:35:05,190 - __main__ - INFO - Retrieving data for category: ORDER_STATUS\n",
      "2025-11-26 23:35:05,190 - __main__ - INFO - Data retrieved successfully for ORDER_STATUS\n",
      "2025-11-26 23:35:05,193 - __main__ - INFO - Generating response\n",
      "2025-11-26 23:35:06,028 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-26 23:35:06,819 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 23:35:06,825 - __main__ - INFO - Response generated successfully\n",
      "2025-11-26 23:35:06,827 - __main__ - INFO - Performing quality check\n",
      "2025-11-26 23:35:07,684 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-26 23:35:08,148 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 23:35:08,153 - root - INFO - Quality score: 9/10\n",
      "2025-11-26 23:35:08,154 - __main__ - INFO - Workflow completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AI Agent Automation Results\n",
      "================================================================================\n",
      "\n",
      "Original Query: What's the status of my order #12345?\n",
      "\n",
      "Category: ORDER_STATUS\n",
      "\n",
      "Retrieved Data: Order tracking system connected. Typical delivery: 3-5 business days.\n",
      "\n",
      "Generated Response: Hello, thank you for reaching out about the status of your order #12345. I've checked on it for you, and I'm happy to inform you that our order tracking system is connected, which means you can expect to receive your order within the next 3-5 business days, typical of our standard delivery timeframe. If you'd like to get a more precise update, I can also provide you with the tracking details so you can monitor the progress of your order directly. Would you like me to send those over to you?/10\n",
      "\n",
      "Quality Score: 9\n",
      "\n",
      "Timestamp: 2025-11-26T23:35:05.188967\n",
      "\n",
      "Metadata: {\n",
      "  \"node\": \"classifier\",\n",
      "  \"status\": \"completed\",\n",
      "  \"retriever\": \"completed\",\n",
      "  \"data_source\": \"knowledge_base\",\n",
      "  \"generator\": \"completed\",\n",
      "  \"quality_checker\": \"completed\",\n",
      "  \"final_status\": \"success\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 23:35:13,954 - __main__ - INFO - Starting agent workflow for query: I need to return a defective product and get a refund\n",
      "2025-11-26 23:35:13,958 - __main__ - INFO - Creating agent workflow graph\n",
      "2025-11-26 23:35:13,975 - __main__ - INFO - Workflow compiled successfully\n",
      "2025-11-26 23:35:13,978 - __main__ - INFO - Classifying query: I need to return a defective product and get a refund\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST CASE 2/5\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 23:35:14,786 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-26 23:35:15,212 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 23:35:15,220 - __main__ - INFO - Query classified as: REFUND\n",
      "2025-11-26 23:35:15,225 - __main__ - INFO - Retrieving data for category: REFUND\n",
      "2025-11-26 23:35:15,227 - __main__ - INFO - Data retrieved successfully for REFUND\n",
      "2025-11-26 23:35:15,232 - __main__ - INFO - Generating response\n",
      "2025-11-26 23:35:16,018 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-26 23:35:16,782 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 23:35:16,787 - __main__ - INFO - Response generated successfully\n",
      "2025-11-26 23:35:16,791 - __main__ - INFO - Performing quality check\n",
      "2025-11-26 23:35:17,612 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-26 23:35:18,077 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 23:35:18,089 - root - INFO - Quality score: 9/10\n",
      "2025-11-26 23:35:18,092 - __main__ - INFO - Workflow completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AI Agent Automation Results\n",
      "================================================================================\n",
      "\n",
      "Original Query: I need to return a defective product and get a refund\n",
      "\n",
      "Category: REFUND\n",
      "\n",
      "Retrieved Data: Refund policy: 30-day return window. Full refund with receipt. Processing time: 5-7 business days.\n",
      "\n",
      "Generated Response: I'm so sorry to hear that you're experiencing issues with your product. I'm here to help you with the return and refund process. Since you're within our 30-day return window, you're eligible for a full refund. To initiate the process, could you please provide me with your receipt and a brief description of the defect? I'll guide you through the next steps and ensure that your refund is processed as quickly as possible, typically within 5-7 business days. Your satisfaction is important to me, and I'm committed to making this right for you./10\n",
      "\n",
      "Quality Score: 9\n",
      "\n",
      "Timestamp: 2025-11-26T23:35:15.223939\n",
      "\n",
      "Metadata: {\n",
      "  \"node\": \"classifier\",\n",
      "  \"status\": \"completed\",\n",
      "  \"retriever\": \"completed\",\n",
      "  \"data_source\": \"knowledge_base\",\n",
      "  \"generator\": \"completed\",\n",
      "  \"quality_checker\": \"completed\",\n",
      "  \"final_status\": \"success\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 23:35:20,073 - __main__ - INFO - Starting agent workflow for query: How long does standard shipping take?\n",
      "2025-11-26 23:35:20,076 - __main__ - INFO - Creating agent workflow graph\n",
      "2025-11-26 23:35:20,093 - __main__ - INFO - Workflow compiled successfully\n",
      "2025-11-26 23:35:20,101 - __main__ - INFO - Classifying query: How long does standard shipping take?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST CASE 3/5\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 23:35:21,059 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-26 23:35:21,461 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 23:35:21,463 - __main__ - INFO - Query classified as: SHIPPING\n",
      "2025-11-26 23:35:21,467 - __main__ - INFO - Retrieving data for category: SHIPPING\n",
      "2025-11-26 23:35:21,469 - __main__ - INFO - Data retrieved successfully for SHIPPING\n",
      "2025-11-26 23:35:21,471 - __main__ - INFO - Generating response\n",
      "2025-11-26 23:35:22,286 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-26 23:35:22,922 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 23:35:22,925 - __main__ - INFO - Response generated successfully\n",
      "2025-11-26 23:35:22,928 - __main__ - INFO - Performing quality check\n",
      "2025-11-26 23:35:23,767 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-26 23:35:24,202 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 23:35:24,207 - root - INFO - Quality score: 9/10\n",
      "2025-11-26 23:35:24,211 - __main__ - INFO - Workflow completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AI Agent Automation Results\n",
      "================================================================================\n",
      "\n",
      "Original Query: How long does standard shipping take?\n",
      "\n",
      "Category: SHIPPING\n",
      "\n",
      "Retrieved Data: Shipping options: Standard (5-7 days, $5.99), Express (2-3 days, $12.99), Overnight ($24.99).\n",
      "\n",
      "Generated Response: You're looking for information on our standard shipping option. I'd be happy to help you with that. Our standard shipping typically takes 5-7 business days to arrive, and it's a cost-effective option at just $5.99. If you have any other questions or would like to explore our other shipping options, such as Express or Overnight, please don't hesitate to ask. I'm here to help. Would you like me to assist you with placing an order or have any other questions about shipping?/10\n",
      "\n",
      "Quality Score: 9\n",
      "\n",
      "Timestamp: 2025-11-26T23:35:21.465565\n",
      "\n",
      "Metadata: {\n",
      "  \"node\": \"classifier\",\n",
      "  \"status\": \"completed\",\n",
      "  \"retriever\": \"completed\",\n",
      "  \"data_source\": \"knowledge_base\",\n",
      "  \"generator\": \"completed\",\n",
      "  \"quality_checker\": \"completed\",\n",
      "  \"final_status\": \"success\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 23:35:25,123 - __main__ - INFO - Starting agent workflow for query: What is your return policy?\n",
      "2025-11-26 23:35:25,132 - __main__ - INFO - Creating agent workflow graph\n",
      "2025-11-26 23:35:25,151 - __main__ - INFO - Workflow compiled successfully\n",
      "2025-11-26 23:35:25,156 - __main__ - INFO - Classifying query: What is your return policy?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST CASE 4/5\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 23:35:25,940 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-26 23:35:26,223 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 23:35:26,227 - __main__ - INFO - Query classified as: POLICY\n",
      "2025-11-26 23:35:26,231 - __main__ - INFO - Retrieving data for category: POLICY\n",
      "2025-11-26 23:35:26,231 - __main__ - INFO - Data retrieved successfully for POLICY\n",
      "2025-11-26 23:35:26,235 - __main__ - INFO - Generating response\n",
      "2025-11-26 23:35:27,070 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-26 23:35:27,863 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 23:35:27,868 - __main__ - INFO - Response generated successfully\n",
      "2025-11-26 23:35:27,871 - __main__ - INFO - Performing quality check\n",
      "2025-11-26 23:35:28,696 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-26 23:35:29,013 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 23:35:29,018 - root - INFO - Quality score: 9/10\n",
      "2025-11-26 23:35:29,021 - __main__ - INFO - Workflow completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AI Agent Automation Results\n",
      "================================================================================\n",
      "\n",
      "Original Query: What is your return policy?\n",
      "\n",
      "Category: POLICY\n",
      "\n",
      "Retrieved Data: Return policy: 30 days, original condition. Warranty: 1 year manufacturer warranty on electronics.\n",
      "\n",
      "Generated Response: I'd be happy to help you with our return policy. At our company, we want to ensure you're completely satisfied with your purchase. If for any reason you're not, you can return your item within 30 days of receipt, as long as it's in its original condition. This means the item should be unused, with all original packaging and accessories included. If you'd like to initiate a return, please don't hesitate to reach out to me directly and I'll guide you through the process. Your satisfaction is our top priority, and I'm here to help. Would you like more information on how to start a return or have any other questions about our policy?/10\n",
      "\n",
      "Quality Score: 9\n",
      "\n",
      "Timestamp: 2025-11-26T23:35:26.229704\n",
      "\n",
      "Metadata: {\n",
      "  \"node\": \"classifier\",\n",
      "  \"status\": \"completed\",\n",
      "  \"retriever\": \"completed\",\n",
      "  \"data_source\": \"knowledge_base\",\n",
      "  \"generator\": \"completed\",\n",
      "  \"quality_checker\": \"completed\",\n",
      "  \"final_status\": \"success\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 23:35:30,226 - __main__ - INFO - Starting agent workflow for query: I'm having trouble logging into my account\n",
      "2025-11-26 23:35:30,226 - __main__ - INFO - Creating agent workflow graph\n",
      "2025-11-26 23:35:30,245 - __main__ - INFO - Workflow compiled successfully\n",
      "2025-11-26 23:35:30,247 - __main__ - INFO - Classifying query: I'm having trouble logging into my account\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST CASE 5/5\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 23:35:31,151 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-26 23:35:31,573 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 23:35:31,578 - __main__ - INFO - Query classified as: TECHNICAL_SUPPORT\n",
      "2025-11-26 23:35:31,580 - __main__ - INFO - Retrieving data for category: TECHNICAL_SUPPORT\n",
      "2025-11-26 23:35:31,584 - __main__ - INFO - Data retrieved successfully for TECHNICAL_SUPPORT\n",
      "2025-11-26 23:35:31,587 - __main__ - INFO - Generating response\n",
      "2025-11-26 23:35:32,338 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-26 23:35:32,935 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 23:35:32,940 - __main__ - INFO - Response generated successfully\n",
      "2025-11-26 23:35:32,943 - __main__ - INFO - Performing quality check\n",
      "2025-11-26 23:35:33,783 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-26 23:35:34,159 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 23:35:34,164 - root - INFO - Quality score: 9/10\n",
      "2025-11-26 23:35:34,166 - __main__ - INFO - Workflow completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AI Agent Automation Results\n",
      "================================================================================\n",
      "\n",
      "Original Query: I'm having trouble logging into my account\n",
      "\n",
      "Category: TECHNICAL_SUPPORT\n",
      "\n",
      "Retrieved Data: Technical support available 24/7. Common issues: password reset, account access, product setup.\n",
      "\n",
      "Generated Response: I'm so sorry to hear that you're having trouble logging into your account. I'm here to help you resolve the issue as quickly as possible. Can you please tell me a bit more about the error message you're seeing or what's happening when you try to log in? In the meantime, I can also offer to guide you through our password reset process, which often resolves login issues. Would you like me to walk you through that?/10\n",
      "\n",
      "Quality Score: 9\n",
      "\n",
      "Timestamp: 2025-11-26T23:35:31.580929\n",
      "\n",
      "Metadata: {\n",
      "  \"node\": \"classifier\",\n",
      "  \"status\": \"completed\",\n",
      "  \"retriever\": \"completed\",\n",
      "  \"data_source\": \"knowledge_base\",\n",
      "  \"generator\": \"completed\",\n",
      "  \"quality_checker\": \"completed\",\n",
      "  \"final_status\": \"success\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "ðŸŽ‰ All test cases completed!\n",
      "\n",
      "\n",
      " To use with your own queries, call: run_agent('your_query_here')\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EXAMPLE USAGE\n",
    "# ============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Set your Groq API key\n",
    "    # os.environ[\"GROQ_API_KEY\"] = \"your_api_key_here\"\n",
    "    \n",
    "    # Check if API key is set\n",
    "    if not Config.GROQ_API_KEY:\n",
    "        print(\"âŒ Error: GROQ_API_KEY not set!\")\n",
    "        print(\"Please set your Groq API key:\")\n",
    "        print(\"export GROQ_API_KEY='your_api_key_here'\")\n",
    "        exit(1)\n",
    "        \n",
    "    # Example queries to test\n",
    "    test_queries = [\n",
    "        \"What's the status of my order #12345?\",\n",
    "        \"I need to return a defective product and get a refund\",\n",
    "        \"How long does standard shipping take?\",\n",
    "        \"What is your return policy?\",\n",
    "        \"I'm having trouble logging into my account\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nðŸ¤– AI Agent Automation with LangGraph\")\n",
    "    print(\"Using Groq API with Llama 3.3 70B\\n\")\n",
    "    \n",
    "    for i, query in enumerate(test_queries, 1):\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"TEST CASE {i}/{len(test_queries)}\")\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        \n",
    "        try:\n",
    "            result = run_agent(query)\n",
    "            display_results(result)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing query: {e}\")\n",
    "        \n",
    "        if i < len(test_queries):\n",
    "            input(\"\\nPress Enter to continue to the next test case...\")\n",
    "            \n",
    "    print(\"\\nðŸŽ‰ All test cases completed!\\n\")\n",
    "    print(\"\\n To use with your own queries, call: run_agent('your_query_here')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaefe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
