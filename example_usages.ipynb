{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54f7ea55",
   "metadata": {},
   "source": [
    "\n",
    "\"\"\"\n",
    "Practical Usage Examples for AI Agent Automation\n",
    "Demonstrates various use cases and integration patterns\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "117f1ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from langgraph_agent import run_agent, display_results, Config\n",
    "from advanced_features import run_enhanced_agent, memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98caadee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXAMPLE 1: BASIC CUSTOMER SUPPORT\n",
    "# ============================================================================\n",
    "def example_basic_support():\n",
    "    \"\"\"\n",
    "    Example1: Basic customer support queries\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXAMPLE 1: Basic Customer Support\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    queries = [\n",
    "        \"What's the status of my order #12345?\",\n",
    "        \"I need to return a defective product\",\n",
    "        \"How long does shipping take?\",\n",
    "    ]\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"\\n Query: {query}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        result = run_agent(query)\n",
    "        \n",
    "        print(f\"üè∑Ô∏è  Category: {result['category']}\")\n",
    "        print(f\"üí¨ Response: {result['response']}\")\n",
    "        print(f\"‚≠ê Quality: {result['quality_score']}/10\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0200414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 18:36:16,786 - langgraph_agent - INFO - Starting agent workflow for query: What's the status of my order #12345?\n",
      "2025-12-01 18:36:16,786 - langgraph_agent - INFO - Creating agent workflow graph\n",
      "2025-12-01 18:36:16,816 - langgraph_agent - INFO - Workflow compiled successfully\n",
      "2025-12-01 18:36:16,841 - langgraph_agent - INFO - Classifying query: What's the status of my order #12345?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXAMPLE 1: Basic Customer Support\n",
      "================================================================================\n",
      "\n",
      "\n",
      " Query: What's the status of my order #12345?\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 18:36:18,218 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:36:18,635 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:18,667 - langgraph_agent - INFO - Query classified as: ORDER_STATUS\n",
      "2025-12-01 18:36:18,672 - langgraph_agent - INFO - Retrieving data for category: ORDER_STATUS\n",
      "2025-12-01 18:36:18,674 - langgraph_agent - INFO - Data retrieved successfully for ORDER_STATUS\n",
      "2025-12-01 18:36:18,677 - langgraph_agent - INFO - Generating response\n",
      "2025-12-01 18:36:19,588 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:36:20,268 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:20,270 - langgraph_agent - INFO - Response generated successfully\n",
      "2025-12-01 18:36:20,274 - langgraph_agent - INFO - Performing quality check\n",
      "2025-12-01 18:36:21,150 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:36:21,597 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:21,602 - root - INFO - Quality score: 9/10\n",
      "2025-12-01 18:36:21,606 - langgraph_agent - INFO - Workflow completed successfully\n",
      "2025-12-01 18:36:21,606 - langgraph_agent - INFO - Starting agent workflow for query: I need to return a defective product\n",
      "2025-12-01 18:36:21,609 - langgraph_agent - INFO - Creating agent workflow graph\n",
      "2025-12-01 18:36:21,628 - langgraph_agent - INFO - Workflow compiled successfully\n",
      "2025-12-01 18:36:21,631 - langgraph_agent - INFO - Classifying query: I need to return a defective product\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè∑Ô∏è  Category: ORDER_STATUS\n",
      "üí¨ Response: Hello, I'd be happy to help you with the status of your order #12345. I've checked on the order tracking system, and it appears that your order is currently in transit. Typically, our deliveries take 3-5 business days to arrive. I can suggest checking the tracking link we provided in your confirmation email for the most up-to-date information. If you have any further questions or concerns, please don't hesitate to reach out. Would you like me to resend the tracking link to you?\n",
      "‚≠ê Quality: 9/10\n",
      "\n",
      "\n",
      " Query: I need to return a defective product\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 18:36:22,424 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:36:23,060 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:23,063 - langgraph_agent - INFO - Query classified as: REFUND\n",
      "2025-12-01 18:36:23,067 - langgraph_agent - INFO - Retrieving data for category: REFUND\n",
      "2025-12-01 18:36:23,067 - langgraph_agent - INFO - Data retrieved successfully for REFUND\n",
      "2025-12-01 18:36:23,072 - langgraph_agent - INFO - Generating response\n",
      "2025-12-01 18:36:23,943 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:36:24,774 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:24,780 - langgraph_agent - INFO - Response generated successfully\n",
      "2025-12-01 18:36:24,783 - langgraph_agent - INFO - Performing quality check\n",
      "2025-12-01 18:36:25,636 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:36:25,975 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:25,986 - root - INFO - Quality score: 9/10\n",
      "2025-12-01 18:36:25,989 - langgraph_agent - INFO - Workflow completed successfully\n",
      "2025-12-01 18:36:25,992 - langgraph_agent - INFO - Starting agent workflow for query: How long does shipping take?\n",
      "2025-12-01 18:36:25,992 - langgraph_agent - INFO - Creating agent workflow graph\n",
      "2025-12-01 18:36:26,017 - langgraph_agent - INFO - Workflow compiled successfully\n",
      "2025-12-01 18:36:26,020 - langgraph_agent - INFO - Classifying query: How long does shipping take?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè∑Ô∏è  Category: REFUND\n",
      "üí¨ Response: I'm so sorry to hear that you've received a defective product. I'm here to help you with the return process. Since you're within our 30-day return window, you can definitely initiate a return for a full refund. To get started, could you please provide me with your order number and a copy of your receipt? Additionally, I'll need a brief description of the issue with the product. Once I receive this information, I'll guide you through the next steps. Please note that our processing time for refunds is 5-7 business days, so you can expect to receive your refund within that timeframe. Your satisfaction is important to me, and I'm committed to making this process as smooth as possible for you.\n",
      "‚≠ê Quality: 9/10\n",
      "\n",
      "\n",
      " Query: How long does shipping take?\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 18:36:26,815 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:36:27,131 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:27,136 - langgraph_agent - INFO - Query classified as: SHIPPING\n",
      "2025-12-01 18:36:27,139 - langgraph_agent - INFO - Retrieving data for category: SHIPPING\n",
      "2025-12-01 18:36:27,141 - langgraph_agent - INFO - Data retrieved successfully for SHIPPING\n",
      "2025-12-01 18:36:27,144 - langgraph_agent - INFO - Generating response\n",
      "2025-12-01 18:36:27,996 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:36:28,642 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:28,645 - langgraph_agent - INFO - Response generated successfully\n",
      "2025-12-01 18:36:28,649 - langgraph_agent - INFO - Performing quality check\n",
      "2025-12-01 18:36:29,479 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:36:29,842 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:29,842 - root - INFO - Quality score: 9/10\n",
      "2025-12-01 18:36:29,850 - langgraph_agent - INFO - Workflow completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè∑Ô∏è  Category: SHIPPING\n",
      "üí¨ Response: I'd be happy to help you with your shipping query. We offer three convenient shipping options to get your order to you quickly. Our Standard shipping takes 5-7 days and costs $5.99, Express shipping takes 2-3 days for $12.99, and Overnight shipping is available for $24.99. Which option sounds best for you, or would you like me to recommend one based on your location?\n",
      "‚≠ê Quality: 9/10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_basic_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d1c6f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXAMPLE 2: CONVERSATION WITH MEMORY\n",
    "# ============================================================================\n",
    "def example_conversation_memory():\n",
    "    \"\"\"\n",
    "    Example 2: Multi-turn conversation with memory\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXAMPLE 2: Conversation with Memory\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    user_id = \"#12345\"\n",
    "    # fist interaction\n",
    "    print(\"Customer: Where is my order?\")\n",
    "    result1 = run_enhanced_agent(\"Where is my order #12345?\", user_id)\n",
    "    print(f\"Agent: {result1['response']}\")\n",
    "    \n",
    "    # Follow up question (context aware)\n",
    "    print(\"\\nCustomer: When will it arrive?\")\n",
    "    result2 = run_enhanced_agent(\"When will it arrive?\", user_id)\n",
    "    print(f\"Agent: {result2['response']}\")\n",
    "    \n",
    "    # Another follow up  \n",
    "    print(\"\\nCustomer: Can I change the delivery address?\")\n",
    "    result3 = run_enhanced_agent(\"Can I change the delivery address?\", user_id)\n",
    "    print(f\"Agent: {result3['response']}\")\n",
    "    \n",
    "    # Show conversation history\n",
    "    print(\"\\n Conversation History\")\n",
    "    history = memory.get_history(user_id)\n",
    "    for i, msg in enumerate(history):\n",
    "        print(f\"{i}.{msg['role']}: {msg['content'][:60]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97815c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 18:36:29,957 - langgraph_agent - INFO - Classifying query: Where is my order #12345?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXAMPLE 2: Conversation with Memory\n",
      "================================================================================\n",
      "\n",
      "Customer: Where is my order?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 18:36:30,667 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:36:31,123 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:31,128 - langgraph_agent - INFO - Query classified as: ORDER_STATUS\n",
      "2025-12-01 18:36:32,429 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:32,434 - langgraph_agent - INFO - Retrieving data for category: ORDER_STATUS\n",
      "2025-12-01 18:36:32,434 - langgraph_agent - INFO - Data retrieved successfully for ORDER_STATUS\n",
      "2025-12-01 18:36:34,299 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:34,302 - langgraph_agent - INFO - Performing quality check\n",
      "2025-12-01 18:36:35,098 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:36:35,452 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:35,456 - root - INFO - Quality score: 9/10\n",
      "2025-12-01 18:36:35,503 - langgraph_agent - INFO - Classifying query: When will it arrive?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: It seems like we're having some trouble locating your order #12345. I've checked on our system, but unfortunately, it's not showing up in our records. Can you please confirm if you've received any order confirmation emails or details from us? Additionally, could you please double-check if the order number is correct? I'm here to help you get to the bottom of this, and I'll do my best to assist you in tracking down your order.\n",
      "\n",
      "Customer: When will it arrive?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 18:36:36,362 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:36:36,701 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:36,706 - langgraph_agent - INFO - Query classified as: ORDER_STATUS\n",
      "2025-12-01 18:36:37,855 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:37,863 - langgraph_agent - INFO - Retrieving data for category: ORDER_STATUS\n",
      "2025-12-01 18:36:37,863 - langgraph_agent - INFO - Data retrieved successfully for ORDER_STATUS\n",
      "2025-12-01 18:36:39,775 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:39,779 - langgraph_agent - INFO - Performing quality check\n",
      "2025-12-01 18:36:40,610 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:36:41,077 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:41,077 - root - INFO - Quality score: 8/10\n",
      "2025-12-01 18:36:41,122 - langgraph_agent - INFO - Classifying query: Can I change the delivery address?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: I understand you're eager to know when your order will arrive. However, I want to follow up on our previous conversation regarding the status of your order #12345. As I mentioned earlier, we're having some trouble locating it in our system. \n",
      "\n",
      "Before I can provide you with an estimated delivery date, I would like to resolve the issue with your order not being found in our records. If you could provide me with any additional information or confirmation regarding your order, I'd be happy to try and assist you further.\n",
      "\n",
      "That being said, typically, our deliveries take 3-5 business days. But I want to ensure that your order is correctly tracked and updated in our system before providing a more specific estimate. Let's work together to resolve this issue, and I'll do my best to get your order back on track. Can you please confirm any details you have about your order, such as the order confirmation email or the date it was placed?\n",
      "\n",
      "Customer: Can I change the delivery address?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 18:36:42,172 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:36:42,464 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:42,467 - langgraph_agent - INFO - Query classified as: ORDER_STATUS\n",
      "2025-12-01 18:36:43,557 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:43,566 - langgraph_agent - INFO - Retrieving data for category: ORDER_STATUS\n",
      "2025-12-01 18:36:43,567 - langgraph_agent - INFO - Data retrieved successfully for ORDER_STATUS\n",
      "2025-12-01 18:36:45,419 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:45,428 - langgraph_agent - INFO - Performing quality check\n",
      "2025-12-01 18:36:46,196 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:36:46,586 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:46,591 - root - INFO - Quality score: 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: I'd be happy to help you with changing the delivery address for your order. However, I want to follow up on our previous conversation regarding the status of your order #12345. As you may recall, we're having some trouble locating it in our system, and I haven't been able to confirm the details of your order yet.\n",
      "\n",
      "Before we proceed with changing the delivery address, I would like to resolve the issue with your order not being found in our records. If you could provide me with any additional information or confirmation regarding your order, such as the order confirmation email or the date it was placed, I'd be happy to try and assist you further.\n",
      "\n",
      "Once we've confirmed the details of your order, I can definitely help you with changing the delivery address. Please note that changing the delivery address may affect the estimated delivery date, which is typically 3-5 business days. But let's take it one step at a time and get your order sorted out first. Can you please provide me with any additional information you have about your order?\n",
      "\n",
      " Conversation History\n",
      "0.user: Where is my order #12345?\n",
      "1.assistant: It seems like we're having some trouble locating your order \n",
      "2.user: When will it arrive?\n",
      "3.assistant: I understand you're eager to know when your order will arriv\n",
      "4.user: Can I change the delivery address?\n",
      "5.assistant: I'd be happy to help you with changing the delivery address \n"
     ]
    }
   ],
   "source": [
    "example_conversation_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60484824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXAMPLE 3: BATCH PROCESSING\n",
    "# ============================================================================\n",
    "def example_batch_processing():\n",
    "    \"\"\"\n",
    "    Example 3: process multiple queries in batch  \n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXAMPLE 3: Batch Processing\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    queries = [\n",
    "        \"Order status for #12345\",\n",
    "        \"Need refund for order #67890\",\n",
    "        \"Technical support needed\",\n",
    "        \"What's your return policy?\",\n",
    "        \"Shipping information needed\"\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    print(\"Processing batch of queries...\\n\")\n",
    "    \n",
    "    for i, query in enumerate(queries, 1):\n",
    "        print(f\"[{i}/{len(queries)}] Processing: {query[:50]}\")\n",
    "        result = run_agent(query)\n",
    "        results.append({\n",
    "            \"query\": query,\n",
    "            \"category\": result['category'],\n",
    "            \"quality_score\": result['quality_score']\n",
    "        })\n",
    "        \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"BATCH PROCESSING SUMMARY\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    avg_quality = sum(r['quality_score'] for r in results) / len(results)\n",
    "    \n",
    "    print(f\"Total Queries: {len(results)}\")\n",
    "    print(f\"Average Quality Score: {avg_quality:.2f}/10\")\n",
    "    \n",
    "    #category distribution\n",
    "    categories = {}\n",
    "    for r in results:\n",
    "        categories[r['category']] = categories.get(r['category'], 0) + 1\n",
    "        \n",
    "    print(\"\\nCategory Distribution:\")\n",
    "    for category, count in categories.items():\n",
    "        percentage = (count / len(results)) * 100\n",
    "        print(f\" - {category}: {count} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73903abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 18:36:47,119 - langgraph_agent - INFO - Starting agent workflow for query: Order status for #12345\n",
      "2025-12-01 18:36:47,121 - langgraph_agent - INFO - Creating agent workflow graph\n",
      "2025-12-01 18:36:47,143 - langgraph_agent - INFO - Workflow compiled successfully\n",
      "2025-12-01 18:36:47,148 - langgraph_agent - INFO - Classifying query: Order status for #12345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXAMPLE 3: Batch Processing\n",
      "================================================================================\n",
      "\n",
      "Processing batch of queries...\n",
      "\n",
      "[1/5] Processing: Order status for #12345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 18:36:48,100 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:36:48,402 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:48,406 - langgraph_agent - INFO - Query classified as: ORDER_STATUS\n",
      "2025-12-01 18:36:48,408 - langgraph_agent - INFO - Retrieving data for category: ORDER_STATUS\n",
      "2025-12-01 18:36:48,408 - langgraph_agent - INFO - Data retrieved successfully for ORDER_STATUS\n",
      "2025-12-01 18:36:48,410 - langgraph_agent - INFO - Generating response\n",
      "2025-12-01 18:36:49,297 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:36:49,913 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:49,921 - langgraph_agent - INFO - Response generated successfully\n",
      "2025-12-01 18:36:49,926 - langgraph_agent - INFO - Performing quality check\n",
      "2025-12-01 18:36:50,951 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:36:51,343 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:51,348 - root - INFO - Quality score: 9/10\n",
      "2025-12-01 18:36:51,351 - langgraph_agent - INFO - Workflow completed successfully\n",
      "2025-12-01 18:36:51,351 - langgraph_agent - INFO - Starting agent workflow for query: Need refund for order #67890\n",
      "2025-12-01 18:36:51,356 - langgraph_agent - INFO - Creating agent workflow graph\n",
      "2025-12-01 18:36:51,392 - langgraph_agent - INFO - Workflow compiled successfully\n",
      "2025-12-01 18:36:51,396 - langgraph_agent - INFO - Classifying query: Need refund for order #67890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5] Processing: Need refund for order #67890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 18:36:52,224 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:36:52,498 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:52,501 - langgraph_agent - INFO - Query classified as: REFUND\n",
      "2025-12-01 18:36:52,504 - langgraph_agent - INFO - Retrieving data for category: REFUND\n",
      "2025-12-01 18:36:52,504 - langgraph_agent - INFO - Data retrieved successfully for REFUND\n",
      "2025-12-01 18:36:52,504 - langgraph_agent - INFO - Generating response\n",
      "2025-12-01 18:36:53,364 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:36:54,087 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:54,093 - langgraph_agent - INFO - Response generated successfully\n",
      "2025-12-01 18:36:54,103 - langgraph_agent - INFO - Performing quality check\n",
      "2025-12-01 18:36:55,057 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:36:55,318 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:55,324 - root - INFO - Quality score: 9/10\n",
      "2025-12-01 18:36:55,324 - langgraph_agent - INFO - Workflow completed successfully\n",
      "2025-12-01 18:36:55,324 - langgraph_agent - INFO - Starting agent workflow for query: Technical support needed\n",
      "2025-12-01 18:36:55,324 - langgraph_agent - INFO - Creating agent workflow graph\n",
      "2025-12-01 18:36:55,340 - langgraph_agent - INFO - Workflow compiled successfully\n",
      "2025-12-01 18:36:55,340 - langgraph_agent - INFO - Classifying query: Technical support needed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5] Processing: Technical support needed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 18:36:56,209 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:36:56,624 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:56,630 - langgraph_agent - INFO - Query classified as: TECHNICAL_SUPPORT\n",
      "2025-12-01 18:36:56,634 - langgraph_agent - INFO - Retrieving data for category: TECHNICAL_SUPPORT\n",
      "2025-12-01 18:36:56,640 - langgraph_agent - INFO - Data retrieved successfully for TECHNICAL_SUPPORT\n",
      "2025-12-01 18:36:56,649 - langgraph_agent - INFO - Generating response\n",
      "2025-12-01 18:36:57,743 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:36:58,566 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:36:58,571 - langgraph_agent - INFO - Response generated successfully\n",
      "2025-12-01 18:36:58,574 - langgraph_agent - INFO - Performing quality check\n",
      "2025-12-01 18:37:00,072 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:37:00,384 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:37:00,389 - root - INFO - Quality score: 9/10\n",
      "2025-12-01 18:37:00,389 - langgraph_agent - INFO - Workflow completed successfully\n",
      "2025-12-01 18:37:00,391 - langgraph_agent - INFO - Starting agent workflow for query: What's your return policy?\n",
      "2025-12-01 18:37:00,393 - langgraph_agent - INFO - Creating agent workflow graph\n",
      "2025-12-01 18:37:00,409 - langgraph_agent - INFO - Workflow compiled successfully\n",
      "2025-12-01 18:37:00,412 - langgraph_agent - INFO - Classifying query: What's your return policy?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5] Processing: What's your return policy?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 18:37:01,444 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:37:01,821 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:37:01,821 - langgraph_agent - INFO - Query classified as: POLICY\n",
      "2025-12-01 18:37:01,831 - langgraph_agent - INFO - Retrieving data for category: POLICY\n",
      "2025-12-01 18:37:01,837 - langgraph_agent - INFO - Data retrieved successfully for POLICY\n",
      "2025-12-01 18:37:01,839 - langgraph_agent - INFO - Generating response\n",
      "2025-12-01 18:37:02,735 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:37:02,916 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-12-01 18:37:02,919 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds\n",
      "2025-12-01 18:37:05,607 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:37:05,612 - langgraph_agent - INFO - Response generated successfully\n",
      "2025-12-01 18:37:05,614 - langgraph_agent - INFO - Performing quality check\n",
      "2025-12-01 18:37:06,558 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:37:06,809 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-12-01 18:37:06,811 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds\n",
      "2025-12-01 18:37:09,190 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:37:09,193 - root - INFO - Quality score: 9/10\n",
      "2025-12-01 18:37:09,197 - langgraph_agent - INFO - Workflow completed successfully\n",
      "2025-12-01 18:37:09,199 - langgraph_agent - INFO - Starting agent workflow for query: Shipping information needed\n",
      "2025-12-01 18:37:09,199 - langgraph_agent - INFO - Creating agent workflow graph\n",
      "2025-12-01 18:37:09,229 - langgraph_agent - INFO - Workflow compiled successfully\n",
      "2025-12-01 18:37:09,234 - langgraph_agent - INFO - Classifying query: Shipping information needed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5] Processing: Shipping information needed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 18:37:10,923 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:37:11,190 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:37:11,198 - langgraph_agent - INFO - Query classified as: SHIPPING\n",
      "2025-12-01 18:37:11,200 - langgraph_agent - INFO - Retrieving data for category: SHIPPING\n",
      "2025-12-01 18:37:11,200 - langgraph_agent - INFO - Data retrieved successfully for SHIPPING\n",
      "2025-12-01 18:37:11,205 - langgraph_agent - INFO - Generating response\n",
      "2025-12-01 18:37:12,691 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:37:12,878 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-12-01 18:37:12,881 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds\n",
      "2025-12-01 18:37:15,489 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:37:15,491 - langgraph_agent - INFO - Response generated successfully\n",
      "2025-12-01 18:37:15,495 - langgraph_agent - INFO - Performing quality check\n",
      "2025-12-01 18:37:16,575 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:37:16,793 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-12-01 18:37:16,793 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds\n",
      "2025-12-01 18:37:19,045 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:37:19,049 - root - INFO - Quality score: 9/10\n",
      "2025-12-01 18:37:19,054 - langgraph_agent - INFO - Workflow completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BATCH PROCESSING SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Total Queries: 5\n",
      "Average Quality Score: 9.00/10\n",
      "\n",
      "Category Distribution:\n",
      " - ORDER_STATUS: 1 (20.0%)\n",
      " - REFUND: 1 (20.0%)\n",
      " - TECHNICAL_SUPPORT: 1 (20.0%)\n",
      " - POLICY: 1 (20.0%)\n",
      " - SHIPPING: 1 (20.0%)\n"
     ]
    }
   ],
   "source": [
    "example_batch_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a551a39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXAMPLE 4: ERROR HANDLING\n",
    "# ============================================================================\n",
    "def example_error_handling():\n",
    "    \"\"\"\n",
    "    Example 4: Error Handling\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXAMPLE 4: Error Handling\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Test various edge cases\n",
    "    test_cases = [\n",
    "        (\"\", \"Empty query\"),\n",
    "        (\"?\" * 500, \"Very long query\"),\n",
    "        (\"asdfjkl;\", \"Nonsense query\"),\n",
    "        (\"What is the meaning of life?\", \"Out of scope query\"),\n",
    "    ]\n",
    "    for query, description in test_cases:\n",
    "        print(f\"\\nTest: {description}\")\n",
    "        print(f\"Query: {query[:50]}...\")\n",
    "        \n",
    "        try:\n",
    "            result = run_agent(query)\n",
    "            print(f\"Success - Category: {result['category']}\")\n",
    "            print(f\"Response preview: {result['response'][:100]}...\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a8926e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 18:41:19,156 - langgraph_agent - INFO - Starting agent workflow for query: \n",
      "2025-12-01 18:41:19,158 - langgraph_agent - INFO - Creating agent workflow graph\n",
      "2025-12-01 18:41:19,179 - langgraph_agent - INFO - Workflow compiled successfully\n",
      "2025-12-01 18:41:19,185 - langgraph_agent - INFO - Classifying query: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXAMPLE 4: Error Handling\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Test: Empty query\n",
      "Query: ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 18:41:20,183 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:41:20,527 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:41:20,533 - langgraph_agent - INFO - Query classified as: ORDER_STATUS\n",
      "2025-12-01 18:41:20,535 - langgraph_agent - INFO - Retrieving data for category: ORDER_STATUS\n",
      "2025-12-01 18:41:20,537 - langgraph_agent - INFO - Data retrieved successfully for ORDER_STATUS\n",
      "2025-12-01 18:41:20,540 - langgraph_agent - INFO - Generating response\n",
      "2025-12-01 18:41:21,400 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:41:22,244 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:41:22,247 - langgraph_agent - INFO - Response generated successfully\n",
      "2025-12-01 18:41:22,251 - langgraph_agent - INFO - Performing quality check\n",
      "2025-12-01 18:41:22,979 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:41:23,549 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:41:23,553 - root - INFO - Quality score: 9/10\n",
      "2025-12-01 18:41:23,558 - langgraph_agent - INFO - Workflow completed successfully\n",
      "2025-12-01 18:41:23,562 - langgraph_agent - INFO - Starting agent workflow for query: ????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????\n",
      "2025-12-01 18:41:23,564 - langgraph_agent - INFO - Creating agent workflow graph\n",
      "2025-12-01 18:41:23,594 - langgraph_agent - INFO - Workflow compiled successfully\n",
      "2025-12-01 18:41:23,598 - langgraph_agent - INFO - Classifying query: ????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success - Category: ORDER_STATUS\n",
      "Response preview: I'd be happy to help you with your order. I've checked on the status, and I'm pleased to inform you ...\n",
      "\n",
      "Test: Very long query\n",
      "Query: ??????????????????????????????????????????????????...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 18:41:24,343 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:41:24,672 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:41:24,677 - langgraph_agent - INFO - Query classified as: GENERAL\n",
      "2025-12-01 18:41:24,683 - langgraph_agent - INFO - Retrieving data for category: GENERAL\n",
      "2025-12-01 18:41:24,684 - langgraph_agent - INFO - Data retrieved successfully for GENERAL\n",
      "2025-12-01 18:41:24,688 - langgraph_agent - INFO - Generating response\n",
      "2025-12-01 18:41:25,471 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:41:25,994 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:41:25,998 - langgraph_agent - INFO - Response generated successfully\n",
      "2025-12-01 18:41:26,001 - langgraph_agent - INFO - Performing quality check\n",
      "2025-12-01 18:41:26,723 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:41:27,007 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:41:27,014 - root - INFO - Quality score: 9/10\n",
      "2025-12-01 18:41:27,017 - langgraph_agent - INFO - Workflow completed successfully\n",
      "2025-12-01 18:41:27,021 - langgraph_agent - INFO - Starting agent workflow for query: asdfjkl;\n",
      "2025-12-01 18:41:27,023 - langgraph_agent - INFO - Creating agent workflow graph\n",
      "2025-12-01 18:41:27,047 - langgraph_agent - INFO - Workflow compiled successfully\n",
      "2025-12-01 18:41:27,047 - langgraph_agent - INFO - Classifying query: asdfjkl;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success - Category: GENERAL\n",
      "Response preview: It seems like your message didn't come through correctly. I'm here to help with any questions or con...\n",
      "\n",
      "Test: Nonsense query\n",
      "Query: asdfjkl;...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 18:41:27,922 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:41:28,335 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:41:28,341 - langgraph_agent - INFO - Query classified as: GENERAL\n",
      "2025-12-01 18:41:28,347 - langgraph_agent - INFO - Retrieving data for category: GENERAL\n",
      "2025-12-01 18:41:28,349 - langgraph_agent - INFO - Data retrieved successfully for GENERAL\n",
      "2025-12-01 18:41:28,353 - langgraph_agent - INFO - Generating response\n",
      "2025-12-01 18:41:29,135 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:41:29,999 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:41:30,004 - langgraph_agent - INFO - Response generated successfully\n",
      "2025-12-01 18:41:30,006 - langgraph_agent - INFO - Performing quality check\n",
      "2025-12-01 18:41:30,783 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:41:31,164 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:41:31,166 - root - INFO - Quality score: 9/10\n",
      "2025-12-01 18:41:31,172 - langgraph_agent - INFO - Workflow completed successfully\n",
      "2025-12-01 18:41:31,173 - langgraph_agent - INFO - Starting agent workflow for query: What is the meaning of life?\n",
      "2025-12-01 18:41:31,175 - langgraph_agent - INFO - Creating agent workflow graph\n",
      "2025-12-01 18:41:31,209 - langgraph_agent - INFO - Workflow compiled successfully\n",
      "2025-12-01 18:41:31,211 - langgraph_agent - INFO - Classifying query: What is the meaning of life?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success - Category: GENERAL\n",
      "Response preview: I'm so sorry, but it seems like your message didn't come through clearly. I'm here to help with any ...\n",
      "\n",
      "Test: Out of scope query\n",
      "Query: What is the meaning of life?...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 18:41:31,953 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:41:32,510 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:41:32,513 - langgraph_agent - INFO - Query classified as: GENERAL\n",
      "2025-12-01 18:41:32,517 - langgraph_agent - INFO - Retrieving data for category: GENERAL\n",
      "2025-12-01 18:41:32,520 - langgraph_agent - INFO - Data retrieved successfully for GENERAL\n",
      "2025-12-01 18:41:32,522 - langgraph_agent - INFO - Generating response\n",
      "2025-12-01 18:41:33,407 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:41:35,043 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:41:35,047 - langgraph_agent - INFO - Response generated successfully\n",
      "2025-12-01 18:41:35,050 - langgraph_agent - INFO - Performing quality check\n",
      "2025-12-01 18:41:35,956 - langgraph_agent - INFO - LLM initialized successfully\n",
      "2025-12-01 18:41:36,364 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-01 18:41:36,367 - root - INFO - Quality score: 9/10\n",
      "2025-12-01 18:41:36,371 - langgraph_agent - INFO - Workflow completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success - Category: GENERAL\n",
      "Response preview: Dear valued customer,\n",
      "\n",
      "I must say, that's a profound question. While our team is dedicated to provid...\n"
     ]
    }
   ],
   "source": [
    "example_error_handling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933ce4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
